# REU2019
This is the entire repository with the project I worked on in 2019 at the New York Institute of Technology. 

Description of Project:
I worked in the Human-centric Data Analytics lab at the New York Institute of Technology. My focus was studying how humans 
use facial motions and features to recognize emotions in others. I developed an experiment using the Tobii X3-120 eye tracker 
that charts the gaze patterns and vision attention of participants as they watch videos of people expressing emotion from the 
CREMA-D database. I was able to create an effective model using a decision trees to classify the emotions expressed in the 
video stimulus using total eye fixation time.
